{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "637c6b02",
   "metadata": {},
   "source": [
    "\n",
    "# Glucose Level Prediction Project\n",
    "\n",
    "This notebook focuses on predicting glucose levels using health-related features from the Framingham dataset. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81766208",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusion / What We Learned\n",
    "\n",
    "- **Exploration**: Key features impacting glucose levels include BMI, blood pressure, and age.\n",
    "- **Modeling**: Several models were trained and tested. Random Forest performed the best.\n",
    "- **Results**: High-performing models can help in early diagnosis and preventive care.\n",
    "- **Impact**: This type of analysis supports better decision-making in healthcare interventions.\n",
    "\n",
    "This project provides a baseline for predictive health analytics and could be expanded with more complex datasets and techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1908eaa",
   "metadata": {},
   "source": [
    "\n",
    "## What To Do\n",
    "\n",
    "1. Import and explore the `framingham.csv` dataset.\n",
    "2. Clean the data (handle nulls, correct formats, etc.).\n",
    "3. Visualize the distribution of glucose and related health indicators.\n",
    "4. Perform feature selection and engineering.\n",
    "5. Train ML models (e.g., Logistic Regression, Decision Tree, Random Forest).\n",
    "6. Evaluate models using classification metrics.\n",
    "7. Predict glucose levels and draw insights.\n",
    "8. Visualize the modelâ€™s important features and performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37b876b",
   "metadata": {},
   "source": [
    "## Importing and Exploring the dataset\n",
    "\n",
    "(also importing required libraries and tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c12e575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('framingham.csv')\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nColumns:\", df.columns.tolist())\n",
    "print(\"\\nNull values:\\n\", df.isnull().sum())\n",
    "print(\"\\nStatistical Summary:\\n\", df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3939a71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes , \"\\n\")\n",
    "\n",
    "missing = df.isnull().sum()\n",
    "print(\"\\n Missing Values:\\n\", missing[missing > 0])\n",
    "\n",
    "df_cleaned = df.copy()\n",
    "num_cols = df_cleaned.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "for col in num_cols:\n",
    "    if df_cleaned[col].isnull().sum() > 0:\n",
    "        median_val = df_cleaned[col].median()\n",
    "        df_cleaned[col].fillna(median_val, inplace=True)\n",
    "\n",
    "#median over means as it is less effected by outlier values\n",
    "\n",
    "print(\"Any remaining nulls?\\n\", df_cleaned.isnull().sum().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8441ac",
   "metadata": {},
   "source": [
    "Filling values instead of removing the null regions. Dropping those null values made a greater impact on the dataset and would make the model less accurate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
