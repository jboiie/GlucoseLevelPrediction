{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "637c6b02",
   "metadata": {},
   "source": [
    "\n",
    "# Glucose Level Prediction Project\n",
    "\n",
    "This notebook focuses on predicting glucose levels using health-related features from the Framingham dataset. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81766208",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusion / What We Learned\n",
    "\n",
    "- **Exploration**: Key features impacting glucose levels include BMI, blood pressure, and age.\n",
    "- **Modeling**: Several models were trained and tested. Random Forest performed the best.\n",
    "- **Results**: High-performing models can help in early diagnosis and preventive care.\n",
    "- **Impact**: This type of analysis supports better decision-making in healthcare interventions.\n",
    "\n",
    "This project provides a baseline for predictive health analytics and could be expanded with more complex datasets and techniques.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1908eaa",
   "metadata": {},
   "source": [
    "\n",
    "## What To Do\n",
    "\n",
    "1. Import and explore the `framingham.csv` dataset.\n",
    "2. Clean the data (handle nulls, correct formats, etc.).\n",
    "3. Visualize the distribution of glucose and related health indicators.\n",
    "4. Perform feature selection and engineering.\n",
    "5. Train ML models (e.g., Logistic Regression, Decision Tree, Random Forest).\n",
    "6. Evaluate models using classification metrics.\n",
    "7. Predict glucose levels and draw insights.\n",
    "8. Visualize the model’s important features and performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37b876b",
   "metadata": {},
   "source": [
    "## Importing and Exploring the dataset\n",
    "\n",
    "(also importing required libraries and tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c12e575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('framingham.csv')\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nColumns:\", df.columns.tolist())\n",
    "print(\"\\nNull values:\\n\", df.isnull().sum())\n",
    "print(\"\\nStatistical Summary:\\n\", df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3939a71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes , \"\\n\")\n",
    "\n",
    "missing = df.isnull().sum()\n",
    "print(\"\\n Missing Values:\\n\", missing[missing > 0])\n",
    "\n",
    "df_cleaned = df.copy()\n",
    "num_cols = df_cleaned.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "for col in num_cols:\n",
    "    if df_cleaned[col].isnull().sum() > 0:\n",
    "        median_val = df_cleaned[col].median()\n",
    "        df_cleaned[col].fillna(median_val, inplace=True)\n",
    "\n",
    "#median over means as it is less effected by outlier values\n",
    "\n",
    "print(\"Any remaining nulls?\\n\", df_cleaned.isnull().sum().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8441ac",
   "metadata": {},
   "source": [
    "Filling values instead of removing the null regions. Dropping those null values made a greater impact on the dataset and would make the model less accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de494867",
   "metadata": {},
   "source": [
    "## Now Plotting and visualizing the data `(EDA)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51d8159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style=\"darkgrid\", palette=\"Set2\")\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(df_cleaned['glucose'], kde=True, bins=30, color='darkgreen')\n",
    "plt.title('Distribution of Glucose Levels')\n",
    "plt.xlabel('Glucose')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d5fe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pair plots of glucose with some important features\n",
    "features_to_plot = ['age', 'BMI', 'heartRate', 'sysBP', 'diaBP', 'glucose']\n",
    "sns.pairplot(df_cleaned[features_to_plot], diag_kind=\"kde\", plot_kws={'alpha':0.6})\n",
    "plt.suptitle(\"Glucose vs Health Indicators\", y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29badcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots to show glucose levels across binary features\n",
    "plt.figure(figsize=(14, 5))\n",
    "binary_features = ['diabetes', 'currentSmoker', 'prevalentHyp', 'TenYearCHD']\n",
    "\n",
    "for i, feature in enumerate(binary_features):\n",
    "    plt.subplot(1, 4, i+1)\n",
    "    sns.boxplot(x=feature, y='glucose', data=df_cleaned, palette='Greens')\n",
    "    plt.title(f'Glucose by {feature}')\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel('Glucose')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230d0010",
   "metadata": {},
   "source": [
    "## Corelation Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60afc27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "correlation_matrix = df_cleaned.corr()\n",
    "\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='Greens', square=True)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754ad922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation of each feature with glucose\n",
    "glucose_corr = correlation_matrix['glucose'].drop('glucose')\n",
    "glucose_corr_sorted = glucose_corr.abs().sort_values(ascending=False)\n",
    "\n",
    "print(\"Top features correlated with glucose:\")\n",
    "print(glucose_corr_sorted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c04a5ad",
   "metadata": {},
   "source": [
    "The most glucose-related feature is clearly `diabetes`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d875c7",
   "metadata": {},
   "source": [
    "## Feature selection and model training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2212cedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting some features only\n",
    "\n",
    "selected_features = [\n",
    "    'diabetes', 'sysBP', 'TenYearCHD', 'age', 'heartRate',\n",
    "    'prevalentHyp', 'BMI', 'diaBP', 'cigsPerDay', 'currentSmoker'\n",
    "]\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = df.dropna(subset=['glucose'])\n",
    "\n",
    "# Fill remaining missing values (for features) with median\n",
    "df.fillna(df.median(), inplace=True)\n",
    "\n",
    "# Selected features + target\n",
    "X = df[selected_features]\n",
    "y = df['glucose']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a741442",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Split the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c70377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Initialize models\n",
    "lr = LinearRegression()\n",
    "dt = DecisionTreeRegressor(random_state=42)\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Train\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "dt.fit(X_train_scaled, y_train)\n",
    "rf.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702c1ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "models = {'Linear Regression': lr, 'Decision Tree': dt, 'Random Forest': rf}\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(f\"{name} — R² Score: {r2:.3f}, RMSE: {rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc07e91",
   "metadata": {},
   "source": [
    "since the r2 values are near 0.0, we find that these models are weak and need tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec1e62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot actual vs predicted for each model\n",
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "for i, (name, model) in enumerate(models.items()):\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    sns.scatterplot(x=y_test, y=y_pred, alpha=0.6, edgecolor='k')\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--r')\n",
    "    plt.xlabel(\"Actual Glucose\")\n",
    "    plt.ylabel(\"Predicted Glucose\")\n",
    "    plt.title(f\"{name}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582aaf0e",
   "metadata": {},
   "source": [
    "## Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787a3631",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4870503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize base model\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf,\n",
    "                           param_grid=param_grid,\n",
    "                           cv=5,\n",
    "                           n_jobs=-1,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           verbose=2)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39487321",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "y_pred_best = best_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0c73a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred_best)\n",
    "mse = mean_squared_error(y_test, y_pred_best)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred_best)\n",
    "\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"MSE: {mse:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R2 Score: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3dd0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.scatterplot(x=y_test, y=y_pred_best)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel(\"Actual Glucose\")\n",
    "plt.ylabel(\"Predicted Glucose\")\n",
    "plt.title(\"Tuned Random Forest: Actual vs Predicted Glucose\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc6b69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = best_model.feature_importances_\n",
    "features = X.columns\n",
    "importance_df = pd.DataFrame({'Feature': features, 'Importance': importances})\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "sns.barplot(data=importance_df, x='Importance', y='Feature')\n",
    "plt.title(\"Feature Importances from Tuned Random Forest\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b151f07",
   "metadata": {},
   "source": [
    "model still does not fucking work ahhhh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba60957",
   "metadata": {},
   "source": [
    "# Trying some way else\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256a586c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from sklearnex import patch_sklearn  \n",
    "\n",
    "# Enable Intel optimizations \n",
    "patch_sklearn()\n",
    "\n",
    "# Load and clean data\n",
    "df = pd.read_csv('framingham.csv')\n",
    "df = df.dropna(subset=['glucose']).copy()\n",
    "\n",
    "# Feature engineering (unchanged, since it's lightweight)\n",
    "def add_features(X):\n",
    "    X = X.copy()\n",
    "    X['BP_ratio'] = X['sysBP'] / (X['diaBP'] + 1e-6)\n",
    "    X['chol_BMI'] = X['totChol'] / (X['BMI'] + 1e-6)\n",
    "    X['MAP'] = X['diaBP'] + 0.4 * (X['sysBP'] - X['diaBP'])\n",
    "    X['PP'] = X['sysBP'] - X['diaBP']\n",
    "    X['age_sysBP'] = X['age'] * X['sysBP']\n",
    "    X['BMI_heartRate'] = X['BMI'] * X['heartRate']\n",
    "    X['smoke_BMI'] = X['currentSmoker'] * X['BMI']\n",
    "    X['age_sq'] = X['age']**2\n",
    "    X['BMI_sq'] = X['BMI']**2\n",
    "    X['log_totChol'] = np.log1p(X['totChol'])\n",
    "    return X\n",
    "\n",
    "# Prepare data (same as before)\n",
    "base_features = ['male', 'age', 'currentSmoker', 'cigsPerDay', 'BPMeds',\n",
    "                 'prevalentHyp', 'diabetes', 'totChol', 'sysBP', 'diaBP',\n",
    "                 'BMI', 'heartRate', 'TenYearCHD']\n",
    "X = df[base_features]\n",
    "X = add_features(X)\n",
    "y = df['glucose']\n",
    "\n",
    "# Remove outliers (top and bottom 1%)\n",
    "lower = y.quantile(0.01)\n",
    "upper = y.quantile(0.99)\n",
    "mask = (y >= lower) & (y <= upper)\n",
    "X, y = X[mask], y[mask]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Efficient Pipeline (reduced complexity)\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('selector', SelectKBest(f_regression, k=15)),  # Fewer features → faster\n",
    "    ('model', RandomForestRegressor(random_state=42, n_jobs=-1, n_estimators=150))  # Fewer trees\n",
    "])\n",
    "\n",
    "# Lighter GridSearch (fewer combinations)\n",
    "param_grid = {\n",
    "    'selector__k': [10, 15],  # Reduced options\n",
    "    'model__max_depth': [None, 10],  # Shallower trees\n",
    "    'model__min_samples_split': [2, 5]  # Simpler splits\n",
    "}\n",
    "\n",
    "# Efficient GridSearch (less exhaustive)\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='r2',\n",
    "    n_jobs=-1,  # Still parallel, but fewer combinations\n",
    "    verbose=1   # Less logging than verbose=2\n",
    ")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluation\n",
    "y_pred = best_model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R-squared: {r2:.2f}\")\n",
    "\n",
    "# Feature importance (unchanged)\n",
    "selected_indices = best_model.named_steps['selector'].get_support(indices=True)\n",
    "feature_names = best_model.named_steps['poly'].get_feature_names_out()[selected_indices]\n",
    "importances = best_model.named_steps['model'].feature_importances_\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Features:\")\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "# Cross-validation (n_jobs=-1 for speed)\n",
    "cv_scores = cross_val_score(best_model, X, y, cv=5, scoring='r2', n_jobs=-1)\n",
    "print(f\"\\nCross-validated R-squared: {cv_scores.mean():.2f} (±{cv_scores.std():.2f})\")\n",
    "\n",
    "# Plot actual vs predicted\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')\n",
    "plt.xlabel('Actual Glucose')\n",
    "plt.ylabel('Predicted Glucose')\n",
    "plt.title('Actual vs Predicted Glucose Levels (Efficient Model)')\n",
    "plt.show()\n",
    "\n",
    "# Save model\n",
    "joblib.dump(best_model, 'efficient_glucose_predictor.joblib')\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf39652",
   "metadata": {},
   "source": [
    "# `This project is paused here due to data quality barriers and diminishing returns on local hardware.`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
